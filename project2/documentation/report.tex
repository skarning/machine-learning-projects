\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{natbib}

\title{Classifying car price ranges with neural networks}
\author{Sivert M. Skarning}
\date{March 2020}

\begin{document}
\maketitle
\clearpage
\tableofcontents
\clearpage

\section{Introduction}
This project will try to find data pre-processing methods and a neural network that best predicts the buying price of a car, based on the car evaluation dataset.
It will also compare performance and anccuracy between decision trees and neural networks on this dataset.
\subsection{Related work}
There are numerous articles that have studied the performance of different modeling techniques with respect to the car evaluation dataset. The article by Sameer Singh\cite{singh2005modeling} discusses the performance of varying training set sizes for different classification methods for the car evaluation sets. Sameer used artificial neural networks, K-nearest neighbour, decision trees and support vector machines in order to classify the acceptability of each car.


An article\cite{perf} also explored the performance of data mining classification methods. Here the authors also focus on the pre-processing of the data. They discuss concepts like data-cleaning, data-transformation and splitting of the data-set.

\section{Method}

\subsection{Data quality}
In order to ensure data quality it is necessary to assess the dataset. In this report we will clean the dataset by removing duplicates and fill missing values. We do this to give the neural network algorithms quality data to analyze\cite{quality}.
\subsubsection{missing values}
After running an r script that counts missing values, we foundt out that there are no missing values. This will save us from doing interpolation or fill with mean method to fill missing values.
\subsubsection{duplicate values}
Duplicate values might give the modeling algorithm an idea that the date counts more than other data. This migh contribute to over-fitting. After running a script that counted duplicates in r, we found out that the dataset did not have any duplicate data.
\subsection{Encoding}
There are three main encodings when working with classification of categorical data\cite{encoding}.
\begin{itemize}
     \item Integer encoding
     \item One Hot encoding
     \item Learned embedding encoding
\end{itemize}

In this project i will explore the performance of One Hot encoding on the car evaluation data set. This encoding method is used when the machine learning algorithm might not be able to understand the relationship between the data. Integer encoding on this dataset gave poor perfomance.

In figure \ref{fig:one-hot-ex} you can see how one hot encoding encodes the lug\_boot size category into numerical values by splitting the categories into seperate columns of data.

  \begin{figure}[h]
    \centering 
    \includegraphics[width=0.6\textwidth]
    {images/one-hot-encoding-example}
    \caption{Excerpt of One Hot Encoding on car evaluation dataset}
    \label{fig:one-hot-ex}
  \end{figure}
\subsection{Artificial Neural Networks(ANN)}
\subsubsection{Opening remarks}  
In this project i decided to use neuralnet in r for the neural network prediction. This is a well know package and it has good resources.

 \begin{figure}[h]
    \centering 
    \includegraphics[width=0.8\textwidth]
    {images/nn1}
    \caption{Artificial Neural Network}
    \label{fig:nn1}
  \end{figure}

\subsubsection{Training data}
After cleaning the dataset and applying one-hot encoding I fit the model to the training data. The calculation of the accuracy of the model was done with the with the result matrix and the original data. This showed an error rate of 64\% wich is worse than the error rate of the decition tree.
 \begin{figure}[h]
    \centering 
    \includegraphics[width=0.8\textwidth]
    {images/nn_res}
    \caption{ANN results}
    \label{fig:nn1}
  \end{figure}
I decided to split the dataset into to different sets. One training set and one testing set. This prediction was done on the training set. This is not accurate of how the model will perform in real life since the model can be highly tuned for this set (over-fitted).
\subsubsection{Test data}
The prediction on the test data will display the accuracy of the model more realistic. A huge gap betweeen accuracy in test data-set and training data-set will be signs of over-fitting.

When running the ANN on the validation data we got an almost identical accuracy. On the training set we got 35.57\% accuracy, when running the model on the validation data we got a 36.67\%. The fact that the two results are so simulare to eachother is a good indicator that the model is not over-fitted.

\subsubsection{K-fold cross-validation}
Even tough the model is not over-fitting i decided to try k-fold cross-validation in order to find the accuracy of the model. Cross-validation is a method for testing the model that used all of the data for testing and all of the data for validation. The way it works is that it splits the dataset into k different parts. It then uses k - 1 parts for training and the last part for validation. Then it repeats it k times in such a wau that all the k-parts has been used in both testing and validation. Then it takes the average accuracy of these models.

In my project I used 10 fold cross validation. Cross validation 
\clearpage
\bibliographystyle{plain}
\bibliography{ref}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End: